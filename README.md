# Tokyo 2021 Olympics Data Engineering Project Using Azure

This project is inspired by Darshil Parmar's guided project [here](https://youtu.be/IaA9YNlg5hM?si=orryZ-qB6LVnRQ9D), focusing on leveraging Azure's Big Data technologies for data processing and analysis.

## Motivation

The goal of this project is to learn and apply various Azure tools for handling large datasets, transforming raw data into actionable insights.

## Technologies Used

- Azure Data Lake Storage (ADLS)
- Azure Data Factory (ADF)
- Azure Databricks
- Azure Synapse Analytics
- Python
- SQL
- Tableau

## Project Overview

1. **Data Acquisition**: Downloaded CSV files from [Kaggle](https://www.kaggle.com/datasets/arjunprasadsarkhel/2021-olympics-in-tokyo/code) and uploaded to Azure Data Factory (ADF).
2. **Data Ingestion**: Ingested raw data into Azure Data Lake Storage (ADLS) using ADF pipelines.   
3. **Data Transformation**: Utilized Azure Databricks with Apache Spark for data transformation and preprocessing, saving results back to ADLS.
4. **Data Analysis**: Analyzed transformed data using SQL and Python within Azure Synapse Analytics.   
5. **Data Visualization**: Visualized analytical results using Tableau for intuitive insights presentation.

## Conclusion

This project provided hands-on experience with Azure's Big Data tools and enhanced skills in data engineering and analytics. Future enhancements could include real-time data processing or integrating additional data sources.

Feel free to reach out with any questions or feedback!
